import struct
import pandas as pd


# osense.py

# Written by Andrew Eichmann, NOAA/NWS/NCEP/EMC

# =============================================================================
# function: read_osense(filename)
#
# Reads osense file generated by enkf and efsoi executables in EFSOI
# implementation in NOAA-EMC/GSI and NOAA-EMC/GSI-Utils, and returns a pandas
# DataFrame with conventional and ozone data, a second DataFrame with satellite
# data, and the date and cycle read from the file. The conventional/ozone data
# and satellite data have different record formats and slightly different
# meanings to the columns, which get hashed out in later scripts.
# The osense file format expected by this fuction is determined by
# enkf_obs_sensitivity module in GSI/src/enkf.  The relevant variable
# declarations in enkf_obs_sensitivity are reproduced below. Two variables
# from enkf that are in the osense file but ignored here are analobs and
# biaspreds - analobs is used by the efsoi algorithm
# =============================================================================

# Structure for observation sensitivity information output
# type obsense_header
#  sequence
#  integer(i_kind) :: idate         ! Base date (initial date)
#  integer(i_kind) :: obsnum        ! Observation number (total)
#  integer(i_kind) :: convnum       ! Observation number (conventional)
#  integer(i_kind) :: oznum         ! Observation number (ozone)
#  integer(i_kind) :: satnum        ! Observation number (satellite)
#  integer(i_kind) :: npred         ! Number of predictors for bias correction
#  integer(i_kind) :: nanals        ! Number of members
# end type obsense_header
#
# where i_kind    - generic specification kind for default integer
# is a long integer


#
# Type definition for observation sensitivity information file
# type obsense_info
#  sequence
#  real(r_single)  :: obfit_prior       ! Observation fit to the first guess
#  real(r_single)  :: obsprd_prior      ! Spread of observation prior
#  real(r_single)  :: ensmean_obnobc    ! Ensemble mean first guess
#                                          (no bias correction)
#  real(r_single)  :: ensmean_ob        ! Ensemble mean first guess
#                                          (bias corrected)
#  real(r_single)  :: ob                ! Observation value
#  real(r_single)  :: oberrvar          ! Observation error variance
#  real(r_single)  :: lon               ! Longitude
#  real(r_single)  :: lat               ! Latitude
#  real(r_single)  :: pres              ! Pressure
#  real(r_single)  :: time              ! Observation time
#  real(r_single)  :: oberrvar_orig     ! Original error variance
#  integer(i_kind) :: stattype          ! Observation type
#  character(len=20) :: obtype          ! Observation element / Satellite name
#  integer(i_kind) :: indxsat           ! Satellite index (channel) set to zero
#  integer(i_kind) :: is_assimilated    ! is assimilated? flag
#  real(r_single)  :: osense_kin        ! Observation sensitivity
#                                       ! (kinetic energy) [J/kg]
#  real(r_single)  :: osense_dry        ! Observation sensitivity
#                                       ! (Dry total energy) [J/kg]
#  real(r_single)  :: osense_moist      ! Observation sensitivity
#                                       ! (Moist total energy) [J/kg]
# end type obsense_info


def read_osense(filename):

    # these names are the same as in enkf_obs_sensitivity, but needn't be,
    # though later processing assumes them
    datacolumns = ['obfit_prior',
                   'obsprd_prior',
                   'ensmean_obnobc',
                   'ensmean_ob',
                   'ob',
                   'oberrvar',
                   'lon',
                   'lat',
                   'pres',
                   'time',
                   'oberrvar_orig',
                   'stattype',
                   'obtype',
                   'indxsat',
                   'assimilated',
                   'osense_kin',
                   'osense_dry',
                   'osense_moist']

# these determine the size of the records read and depend on the formatting
    headerf = '<LLLLLLL'
    recordf = '=fffffffffffl20sllfff'

    header_size = struct.calcsize(headerf)
    osense_info_size = struct.calcsize(recordf)

    convdatatmp = []
    satdatatmp = []

    print('reading file ', filename)

    with open(filename, 'rb') as fin:

        # first read the header for info about the records

        # this seems to be header info, read and ignored
        f = fin.read(4)
        header = fin.read(header_size)
        (idate, obsnum, convnum, oznum, satnum, npred, nanals) = \
            struct.unpack(headerf, header)
        analobsf = '=' + 'f' * nanals
        analobs_size = struct.calcsize(analobsf)
        biaspredsf = '=' + 'f' * (npred + 1)
        biaspreds_size = struct.calcsize(biaspredsf)

        print('read header: idate = ', idate, ', convnum + oznum = ',
              convnum + oznum, ', satnum = ', satnum, ' npred = ', npred,
              ', nanals = ', nanals, ' obsnum = ', obsnum,
              ', should equal convnum + oznum + satnum: ',
              convnum + oznum + satnum)

        # now read the conventional data records

        print('reading conventional data...')
        for i in range(0, convnum + oznum):

            # this seems to be header info, read and ignored
            f = fin.read(8)
            record = fin.read(osense_info_size)
            # read and ignored
            analobs = fin.read(analobs_size)
            convdatarecord = struct.unpack(recordf, record)
            # pull out and clean up obtype
            obtype = str(convdatarecord[12])[2:-1].strip()
            convdatarecord = convdatarecord[0:12] + (obtype,) + \
                convdatarecord[13:]
            convdatatmp.append(convdatarecord)

        print('reading satellite data...')
        for i in range(0, satnum):

            # this seems to be header info, read and ignored
            f = fin.read(8)
            record = fin.read(osense_info_size)
            # read and ignored
            analobs = fin.read(analobs_size)
            # read and ignored
            biaspreds = fin.read(biaspreds_size)
            satdatarecord = struct.unpack(recordf, record)
            # pull out and clean up obtype
            obtype = str(satdatarecord[12])[2:-1].strip()
            satdatarecord = satdatarecord[0:12] + (obtype,) + \
                satdatarecord[13:]
            satdatatmp.append(satdatarecord)

    convdata = pd.DataFrame(convdatatmp, columns=datacolumns)

    satdata = pd.DataFrame(satdatatmp, columns=datacolumns)

# for sanity check
    print(convdata.describe())
    print(satdata.describe())

    return((convdata, satdata, idate))


def consolidate(convdata, satdata, sensors='Default', osensefields='Default'):
    # takes convdata and satdata osense DataFrames and joins them in a single
    # internally consistant DataFrame

    # these are satellite sensors to consolidate across plaforms
    if sensors == 'Default':
        sensors = ['airs',
                   'amsr',
                   'amsua',
                   'atms',
                   'avhrr',
                   'cris',
                   'iasi',
                   'mhs',
                   'saphir',
                   'seviri',
                   'ssmis']

    # these are fields in the osense files and can be expanded or reduced
    if osensefields == 'Default':
        osensefields = ['source',
                        'detailed_source',
                        'indxsat',
                        'osense_kin',
                        'osense_dry',
                        'osense_moist',
                        'assimilated',
                        'lat',
                        'lon',
                        'pres']

    # the following is to provide "sensor-platform" in the detailed_source
    # column and "sensor" in the source column
    satdata['detailed_source'] = satdata['obtype']
    satdata['source'] = satdata['obtype']

    for sensor in sensors:
        mask = satdata.source.str.contains(sensor)
        satdata.loc[mask, 'source'] = sensor.upper()

    # csv file should be in repo with osense.py; there should be a more
    # generalizable way to tell it where
    convcodes = pd.read_csv('convdata_codes.csv')

    # associate each data point with its source, by code
    # this also effectively adds the columns 'source' and 'detailed_source'
    convbycodes = pd.merge(convdata, convcodes, how='left',
                           left_on='stattype',
                           right_on='code')

    # drop message='NA'/message02='Empty'
    # data not dumped/not used
    indices = convbycodes[convbycodes['source'] == 'Empty'].index
    convbycodes.drop(indices, inplace=True)

    # some stattypes, namely 700, have no corresponding code, and so have
    # nans in the code, source, and detailed_source fields. This replaces those
    # fields with the stattype
    nanmask = convbycodes.code.isna()
    nanstattypes = convbycodes.loc[nanmask, ['stattype']]
    for nanstattype in nanstattypes.stattype.unique():
        convbycodes.loc[convbycodes['stattype'] == nanstattype,
                        ['source', 'detailed_source']] = nanstattype

    osensedata = pd.concat([satdata[osensefields],
                            convbycodes[osensefields]])
    return(osensedata)
